from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import GridSearchCV

# Load the training and test data
with open('/mnt/data/agedetector_group_train.v1.0.txt', 'r', encoding='utf-8') as f:
    train_data = f.readlines()

with open('/mnt/data/test.txt', 'r', encoding='utf-8') as f:
    test_data = f.readlines()
    
# Preprocess the data
def preprocess_data(data):
    labels = [line.split()[0][9:] for line in data]
    texts = [' '.join(line.split()[1:]) for line in data]
    return texts, labels

train_texts, train_labels = preprocess_data(train_data)
test_texts, test_labels = preprocess_data(test_data)

# Convert the texts into a matrix of token counts with TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer()
X_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)
X_test_tfidf = tfidf_vectorizer.transform(test_texts)

# Define the parameter grid for GridSearchCV
param_grid = {'alpha': [0.001, 0.01, 0.1, 0.5, 1, 2, 5]}

# Create the GridSearchCV object
grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')

# Fit the grid search to the data
grid_search.fit(X_train_tfidf, train_labels)

# Get the best parameters and score
best_params = grid_search.best_params_
best_score = grid_search.best_score_

# Build a Naive Bayes model with the best parameters
nb_best = MultinomialNB(alpha=best_params['alpha'])
nb_best.fit(X_train_tfidf, train_labels)

# Predict on the test set
test_preds_best = nb_best.predict(X_test_tfidf)

# Evaluate the model
accuracy_best = accuracy_score(test_labels, test_preds_best)
classification_rep_best = classification_report(test_labels, test_preds_best)

best_params, best_score, accuracy_best, classification_rep_best
